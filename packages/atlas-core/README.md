# @atlas/core

**ATLAS コアライブラリ - 統計的会話分析エンジン**

学習不要のリアルタイム重要発話検出システム

---

## 📚 目次

1. [概要](#概要)
2. [アーキテクチャ](#アーキテクチャ)
3. [アルゴリズムの詳細](#アルゴリズムの詳細)
4. [主要コンポーネント](#主要コンポーネント)
5. [API リファレンス](#api-リファレンス)
6. [パラメータ調整ガイド](#パラメータ調整ガイド)
7. [パフォーマンス最適化](#パフォーマンス最適化)
8. [トラブルシューティング](#トラブルシューティング)

---

## 概要

`@atlas/core` は、会話から統計的に有意な重要発話を検出するためのコアライブラリです。機械学習モデルの訓練を必要とせず、埋め込みベースの損失計算とFDR制御による多重検定補正で、リアルタイムに重要発話を抽出します。

### 核となるアイデア

> **「ある発話を履歴から除外したとき、現在の発話の予測が困難になるなら、その発話は重要である」**

これを **Masked Language Modeling (MLM)** と **統計的仮説検定** で定量化します。

### 主な機能

- 📊 **統計的重要度検出** - 帰無分布生成とp値による厳密な検定
- 🧠 **埋め込みベース分析** - OpenAI `text-embedding-3-small` による情報量測定
- ⚡ **リアルタイム処理** - 学習フェーズなし、即座に分析可能
- 🎯 **アンカーメモリ** - 過去の重要発話を長期記憶として活用
- 🔌 **モデルアダプタ** - OpenAI/独自モデルに対応可能
- 🛠️ **完全型安全** - TypeScriptで完全に型付け
- ⚡ **パフォーマンス最適化** - バッチAPI、並列処理、キャッシング

---

## アーキテクチャ

### ディレクトリ構造

```
@atlas/core/src/
├── analyzer/                      # 会話分析モジュール
│   ├── adapters/                 # モデルアダプタ
│   │   ├── types.ts             # ModelAdapter型定義
│   │   ├── openai-adapter.ts    # OpenAI実装（バッチAPI対応）
│   │   ├── fallback-adapter.ts  # フォールバック実装
│   │   └── index.ts
│   ├── statistics/               # 統計関数
│   │   ├── robust.ts            # ロバスト統計 (median, robustZ)
│   │   ├── fdr.ts               # FDR制御 (ecdf, benjaminiHochberg)
│   │   └── time-decay.ts        # 時間減衰 (timeDecayWeight)
│   ├── utils/                    # 汎用ユーティリティ
│   │   ├── math.ts              # 数学関数 (cosine)
│   │   └── array.ts             # 配列操作 (shuffle)
│   ├── scoring/                  # スコアリング
│   │   ├── types.ts             # ScoreDetail, ScoredUtterance
│   │   └── scorer.ts            # スコアリングロジック
│   ├── analyzer.ts               # コア分析関数
│   ├── analyze-with-anchors.ts   # アンカー統合版
│   ├── anchor-memory.ts          # アンカーメモリクラス
│   ├── diversify.ts              # MMR多様化
│   ├── null-samples.ts           # 帰無サンプル生成
│   ├── types.ts                  # Analyzer設定型
│   └── index.ts                  # 公開API
├── format/                        # UI用ユーティリティ
│   └── time.ts                   # 相対時間表示
├── types.ts                       # コア型定義 (Utterance)
└── index.ts                       # パッケージエントリ
```

### データフロー

```
入力: history (過去の発話), current (現在の発話)
  ↓
┌─────────────────────────────────────────┐
│ 1. 候補発話の選択                         │
│    - 直近k文（デフォルト k=15）            │
└─────────────────────────────────────────┘
  ↓
┌─────────────────────────────────────────┐
│ 2. Base Loss計算（バッチAPI）             │
│    L(Y|H) = 1 - cos(H̄, Y)               │
│    H̄: 履歴の重み付き平均埋め込み            │
└─────────────────────────────────────────┘
  ↓
┌─────────────────────────────────────────┐
│ 3. Masked Loss計算（並列実行）            │
│    各候補 u について：                    │
│    L(Y|H\{u}) = 1 - cos(H̄_{-u}, Y)      │
│    ΔL(u) = L(Y|H\{u}) - L(Y|H)          │
└─────────────────────────────────────────┘
  ↓ 並列実行
┌─────────────────────────────────────────┐
│ 4. 帰無サンプル生成（並列実行）              │
│    - 履歴をシャッフルしてN回繰り返し         │
│    - ランダムなΔLを計算                    │
└─────────────────────────────────────────┘
  ↓
┌─────────────────────────────────────────┐
│ 5. スコア計算                             │
│    - 時間減衰重み付け                      │
│    - 最終スコア = ΔL × ageWeight          │
└─────────────────────────────────────────┘
  ↓
┌─────────────────────────────────────────┐
│ 6. 統計的検定                             │
│    - Robust Z変換（MADベース）             │
│    - ECDFによるp値計算                    │
│    - p < fdrAlpha なら有意と判定           │
└─────────────────────────────────────────┘
  ↓
出力: important (有意な重要発話), scored (全スコア)
```

---

## アルゴリズムの詳細

### 1. 埋め込み空間での損失近似

**基本方針:** 言語モデルの予測損失を埋め込みのコサイン類似度で近似

```typescript
// OpenAIAdapter.lossWithHistory()
L(Y|H) ≈ 1 - cos(H̄, Y)
```

**重み付き平均の計算:**

```typescript
// 時間減衰を考慮した重み
w_i = exp(-λ × distance_i)
λ = ln(2) / halfLifeTurns

// 重み付き平均埋め込み
H̄ = Σ_i (w_i × h_i) / Σ_i w_i
```

**実装:**

```typescript
// packages/atlas-core/src/analyzer/adapters/openai-adapter.ts
async lossWithHistory(history: Utterance[], current: Utterance): Promise<number> {
  // 全てのテキストを一括で取得（バッチAPI）
  const allTexts = [...history.map(h => h.text), current.text];
  const allVecs = await this.embedBatch(allTexts);  // ⭐ バッチAPI

  const historyVecs = allVecs.slice(0, history.length);
  const currentVec = allVecs[history.length];

  // 時間減衰を考慮した重み付き平均ベクトルを計算
  const weights = this.computeTemporalWeights(historyVecs.length);
  const avgVec = this.weightedAverageVectors(historyVecs, weights);

  const similarity = this.cosineSimilarity(avgVec, currentVec);
  return 1 - similarity;
}
```

### 2. マスク損失の差分（ΔLoss）

**定義:**

```
ΔL(u) = L(Y|H\{u}) - L(Y|H)
```

- `L(Y|H\{u})`: 発話uを除外した履歴からの損失
- **正の値**: uを除外すると予測が困難（= 重要）
- **負の値**: uは冗長

**実装:**

```typescript
// packages/atlas-core/src/analyzer/scoring/scorer.ts
export const scoreUtterances = async (
  adapter: ModelAdapter,
  history: Utterance[],
  current: Utterance,
  candidates: Utterance[],
  baseLoss: number,
  options: Required<AnalyzerOptions>
): Promise<ScoreDetail[]> => {
  // 並列処理: 全候補のmaskedLossを同時に計算
  const maskedLosses = await Promise.all(
    candidates.map(u => adapter.maskedLoss(history, current, u))
  );

  const details: ScoreDetail[] = candidates.map((u, i) => {
    const masked = maskedLosses[i];
    const delta = masked - baseLoss;  // ⭐ 劣化量

    // 時間減衰重み
    const ageTurns = history.length - history.indexOf(u);
    const ageW = timeDecayWeight(ageTurns, options.halfLifeTurns);

    // 最終スコア
    const raw = options.alphaMix * delta;
    const final = raw * ageW;

    return { baseLoss, maskedLoss: masked, deltaLoss: delta, ageWeight: ageW, rawScore: raw, finalScore: final };
  });

  return details;
};
```

### 3. 帰無サンプル生成

**目的:** 統計的検定のための帰無分布を構築

**アルゴリズム:**

1. 履歴をシャッフル（`nullSamples`回）
2. 各回で直近k文を選択
3. ΔLossを計算
4. 全サンプルをフラット化

**実装:**

```typescript
// packages/atlas-core/src/analyzer/null-samples.ts
export const generateNullSamples = async (
  adapter: ModelAdapter,
  history: Utterance[],
  current: Utterance,
  options: Required<AnalyzerOptions>
): Promise<number[]> => {
  // 並列処理: 各サンプルを同時に生成
  const samplePromises = Array.from({ length: options.nullSamples }, async () => {
    const shuffled = shuffle(history);
    const sample = shuffled.slice(-Math.min(options.k, shuffled.length));

    // baseLossと全maskedLossを並列計算
    const [baseNull, ...maskedLosses] = await Promise.all([
      adapter.lossWithHistory(shuffled, current),
      ...sample.map(u => adapter.maskedLoss(shuffled, current, u)),
    ]);

    return maskedLosses.map(ml => ml - baseNull);  // ⭐ ΔLoss
  });

  const allSamples = await Promise.all(samplePromises);
  return allSamples.flat();  // [ΔL_1, ΔL_2, ..., ΔL_N×k]
};
```

### 4. Robust Z変換

**目的:** 外れ値に頑健な標準化

**標準のZ変換の問題:**
```
z = (x - μ) / σ  // 平均・標準偏差は外れ値に弱い
```

**Robust Z変換:**
```
z = 0.6745 × (x - median(X)) / MAD(X)
```

- `MAD = median(|x_i - median(x)|)`: Median Absolute Deviation
- `0.6745`: 正規分布での対応係数

**実装:**

```typescript
// packages/atlas-core/src/analyzer/statistics/robust.ts
export const robustZ = (values: number[]): number[] => {
  const med = median(values);
  const abs = values.map(v => Math.abs(v - med));
  const mad = median(abs) || 1e-9;  // ゼロ除算防止
  return values.map(v => 0.6745 * ((v - med) / mad));
};
```

### 5. p値計算

**経験的p値:**

```
p = P(X_null > x_obs)
  = 1 - F_0(x_obs)
  = 1 - ECDF_null(x_obs)
```

**実装:**

```typescript
// packages/atlas-core/src/analyzer/analyzer.ts
export const analyze = async (...): Promise<AnalyzeResult> => {
  // ...スコア計算...

  // 並列処理: スコア計算と帰無サンプル生成を同時実行
  const [details, nullScores] = await Promise.all([
    scoreUtterances(adapter, history, current, candidates, baseLoss, opts),
    generateNullSamples(adapter, history, current, opts),
  ]);

  // Robust Z変換
  const finals = details.map(d => d.finalScore);
  const z = robustZ([...finals, ...nullScores]);
  const zFinals = z.slice(0, finals.length);
  const zNull = z.slice(finals.length);

  // ECDF構築とp値計算
  const F0 = ecdf(zNull);
  const pvals = zFinals.map(v => 1 - F0(v));  // ⭐ p = P(X_null > x_obs)

  // 有意性判定
  const important = scored.filter(s => s.p !== undefined && s.p < opts.fdrAlpha);

  return { important, scored, nullScores };
};
```

### 6. 時間減衰関数

**指数減衰:**

```
w(t) = exp(-λt)
λ = ln(2) / halfLife
```

**例:** `halfLife = 10`の場合
- t=0: w=1.0（最新）
- t=10: w=0.5（半減期）
- t=20: w=0.25
- t=30: w=0.125

**実装:**

```typescript
// packages/atlas-core/src/analyzer/statistics/time-decay.ts
export const timeDecayWeight = (ageTurns: number, halfLifeTurns: number): number => {
  const lambda = Math.log(2) / Math.max(1, halfLifeTurns);
  return Math.exp(-lambda * ageTurns);
};
```

---

## 主要コンポーネント

### OpenAIAdapter

**バッチAPI最適化:**

```typescript
// Before: N+1回のHTTPリクエスト
const historyVecs = await Promise.all(history.map(h => this.embed(h.text)));
const currentVec = await this.embed(current.text);

// After: 1回のバッチリクエスト
const allVecs = await this.embedBatch([...history.map(h => h.text), current.text]);
```

**改善:** 90%以上の高速化

**実装:**

```typescript
// packages/atlas-core/src/analyzer/adapters/openai-adapter.ts
async embedBatch(texts: string[]): Promise<number[][]> {
  // キャッシュチェック
  const uncachedIndices: number[] = [];
  const uncachedTexts: string[] = [];
  const results: number[][] = new Array(texts.length);

  for (let i = 0; i < texts.length; i++) {
    const cached = this.cache.get(texts[i]);
    if (cached !== undefined) {
      results[i] = cached;
    } else {
      uncachedIndices.push(i);
      uncachedTexts.push(texts[i]);
    }
  }

  if (uncachedTexts.length === 0) return results;

  // バッチAPI呼び出し
  const response = await fetch('https://api.openai.com/v1/embeddings', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      Authorization: `Bearer ${this.apiKey}`,
    },
    body: JSON.stringify({
      input: uncachedTexts,  // ⭐ 配列で送信
      model: this.model,
      dimensions: this.embeddingDimension,
    }),
  });

  const data = await response.json();
  const embeddings = data.data.map((item: { embedding: number[] }) => item.embedding);

  // キャッシュして結果に格納
  for (let i = 0; i < uncachedTexts.length; i++) {
    const embedding = embeddings[i];
    this.cache.set(uncachedTexts[i], embedding);
    results[uncachedIndices[i]] = embedding;
  }

  return results;
}
```

### AnchorMemory

**用途:** セッション横断で重要発話を記憶

```typescript
// packages/atlas-core/src/analyzer/anchor-memory.ts
export class AnchorMemory {
  private anchors: Anchor[] = [];

  constructor(private maxSize = 200) {}

  add(a: Anchor): void {
    this.anchors.push(a);
    this.anchors.sort((x, y) => y.score - x.score);  // スコア降順
    if (this.anchors.length > this.maxSize) this.anchors.pop();
  }

  top(n = 10): Anchor[] {
    return this.anchors.slice(0, n);
  }

  all(): Anchor[] {
    return [...this.anchors];
  }
}
```

### MMR多様化

**Maximal Marginal Relevance:**

```
MMR(u) = λ × relevance(u) - (1 - λ) × max_sim(u, selected)
```

- `λ → 1`: 重要度優先
- `λ → 0`: 多様性優先

**実装:**

```typescript
// packages/atlas-core/src/analyzer/diversify.ts
export const mmrDiversify = async (
  items: ScoredUtterance[],
  embedder: (text: string) => Promise<number[]>,
  k: number,
  lambda = 0.7
): Promise<ScoredUtterance[]> => {
  const vecs = await Promise.all(items.map(i => embedder(i.text)));
  const chosen: number[] = [];
  const pool = new Set(items.map((_, idx) => idx));

  while (chosen.length < k && pool.size) {
    let bestIdx = -1;
    let bestScore = -Infinity;

    for (const idx of pool) {
      const relevance = items[idx].score;

      // 既に選択された発話との最大類似度
      let diversity = 0;
      for (const j of chosen) {
        diversity = Math.max(diversity, cosine(vecs[idx], vecs[j]));
      }

      const mmr = lambda * relevance - (1 - lambda) * diversity;

      if (mmr > bestScore) {
        bestScore = mmr;
        bestIdx = idx;
      }
    }

    if (bestIdx === -1) break;
    chosen.push(bestIdx);
    pool.delete(bestIdx);
  }

  return chosen.map(i => items[i]);
};
```

---

## API リファレンス

### 型定義

#### `Utterance`

```typescript
type Utterance = {
  id: number;        // 発話ID
  text: string;      // 発話テキスト
  timestamp: number; // タイムスタンプ（ミリ秒）
  speaker: string;   // 発話者
};
```

#### `AnalyzerOptions`

```typescript
type AnalyzerOptions = {
  k?: number;                // 直近k文を厳密評価 (default: 15)
  alphaMix?: number;         // 損失重視度 0..1 (default: 0.6)
  halfLifeTurns?: number;    // 半減期ターン数 (default: 20)
  nullSamples?: number;      // 帰無サンプル数 (default: 20)
  fdrAlpha?: number;         // FDR閾値 (default: 0.1)
  mmrLambda?: number;        // MMR重要度重視度 (default: 0.7)
};
```

#### `ScoredUtterance`

```typescript
type ScoredUtterance = Utterance & {
  rank: number;    // ランク（スコア順位）
  score: number;   // 最終スコア
  p?: number;      // p値
  detail: {
    baseLoss: number;      // 基準損失
    maskedLoss: number;    // マスク損失
    deltaLoss: number;     // 差分損失
    ageWeight: number;     // 時間減衰重み
    rawScore: number;      // 生スコア
    finalScore: number;    // 最終スコア
  };
};
```

### 主要関数

#### `analyze()`

```typescript
function analyze(
  adapter: ModelAdapter,
  history: Utterance[],
  current: Utterance,
  options?: AnalyzerOptions
): Promise<AnalyzeResult>
```

#### `analyzeWithAnchors()`

```typescript
function analyzeWithAnchors(
  adapter: ModelAdapter,
  history: Utterance[],
  current: Utterance,
  anchorMemory: AnchorMemory,
  options?: AnalyzerOptions
): Promise<AnalyzeResult>
```

---

## パラメータ調整ガイド

### `k` (候補発話数)

**デフォルト:** 15

**効果:** 何文前までを候補として評価するか

- **小さい値（k=5）:**
  - 最近の発話のみに集中
  - 計算コスト低
  - 古い重要発話を見逃す可能性

- **大きい値（k=30）:**
  - 広範囲から検出
  - 計算コスト増加
  - ノイズ増加の可能性

**推奨:**
- 短い会話（<20発話）: `k=5-10`
- 通常の会話（20-50発話）: `k=15`（デフォルト）
- 長い会話（>50発話）: `k=20-30`

### `alphaMix` (損失ミックス比)

**デフォルト:** 0.6

**効果:** 損失ベーススコアとサプライザルの混合比

```
rawScore = alphaMix × ΔLoss + (1 - alphaMix) × surprisal
```

- **高い値（0.8）:** コンテキスト依存性を重視
- **低い値（0.4）:** 意外性を重視

**推奨:** `alphaMix = 0.6`（バランス重視）

### `halfLifeTurns` (時間減衰半減期)

**デフォルト:** 20

**効果:** 何ターンで重みが半減するか

- **短い半減期（10）:**
  - 最近の文脈を重視
  - リアルタイムチャット向け

- **長い半減期（30）:**
  - 長期的な文脈を保持
  - 議論・ミーティング向け

**推奨:**
- チャット: `halfLifeTurns=10-15`
- ミーティング: `halfLifeTurns=20-30`

### `nullSamples` (帰無サンプル数)

**デフォルト:** 20

**効果:** 統計的検定の精度

- **少ない（10）:**
  - 高速
  - p値の精度低下

- **多い（100）:**
  - 高精度
  - 計算コスト増加

**推奨:**
- 開発・デバッグ: `nullSamples=10`
- 本番環境: `nullSamples=20-50`

### `fdrAlpha` (p値閾値)

**デフォルト:** 0.1

**効果:** 有意性判定の厳しさ

- **厳しい（0.05）:**
  - 偽陽性が少ない
  - 重要発話を見逃す可能性

- **緩い（0.15）:**
  - より多くの候補を検出
  - ノイズが増える

**推奨:** `fdrAlpha = 0.1`（標準的な統計的有意水準）

---

## パフォーマンス最適化

### 1. Embeddings バッチ取得 ⭐ **最大の効果**

**改善:** N+1回のAPIリクエスト → 1回のバッチリクエスト

**効果:** 90%以上の高速化

### 2. 並列処理

**スコア計算と帰無サンプル生成を並列実行:**

```typescript
const [details, nullScores] = await Promise.all([
  scoreUtterances(adapter, history, current, candidates, baseLoss, opts),
  generateNullSamples(adapter, history, current, opts),
]);
```

**改善:** 約2倍高速化

### 3. キャッシュ戦略

**OpenAIAdapter は埋め込みをキャッシュ:**

```typescript
private cache: Map<string, number[]> = new Map();

async embed(text: string): Promise<number[]> {
  const cached = this.cache.get(text);
  if (cached !== undefined) return cached;
  // API呼び出し...
  this.cache.set(text, embedding);
  return embedding;
}
```

**効果:** 同じテキストの再計算を回避

### 4. 計算量削減

**直近k文のみ評価:**

```typescript
const candidates = history.slice(-opts.k);  // O(k) instead of O(n)
```

**効果:** 会話が長くなっても計算量が一定

### パフォーマンス指標

**計算量:** O(k × nullSamples) per utterance

**典型的なレイテンシ**（OpenAIAdapter使用時）:
- 初回: ~200-500ms（埋め込みAPI呼び出し）
- 2回目以降: ~50-100ms（キャッシュヒット）

**メモリ使用量:**
- AnchorMemory: ~200個 × 1.5KB = 300KB
- 埋め込みキャッシュ: ~100発話 × 6KB = 600KB

---

## トラブルシューティング

### 重要発話が検出されない

**原因:**
1. `fdrAlpha`が厳しすぎる
2. 会話が短すぎる（<10発話）
3. `nullSamples`が少なすぎてp値が不正確

**解決策:**
```typescript
const result = await analyze(adapter, history, current, {
  fdrAlpha: 0.15,      // 閾値を緩める
  nullSamples: 50,     // サンプル数を増やす
});
```

### 計算が遅い

**原因:**
1. `nullSamples`が多すぎる
2. `k`が大きすぎる
3. 埋め込みキャッシュが効いていない

**解決策:**
```typescript
const result = await analyze(adapter, history, current, {
  k: 10,              // 候補数を減らす
  nullSamples: 10,    // サンプル数を減らす
});
```

### p値が常に1.0になる

**原因:** 帰無分布とスコア分布が重なっている

**確認:**
```typescript
console.log('Null scores:', result.nullScores);
console.log('Final scores:', result.scored.map(s => s.score));
```

**解決策:**
- パラメータ調整（`alphaMix`, `halfLifeTurns`）
- より長い会話で試す

---

## 使用例

### 基本的な使用

```typescript
import { analyze, OpenAIAdapter, type Utterance } from '@atlas/core';

const adapter = new OpenAIAdapter({ apiKey: process.env.OPENAI_API_KEY });

const history: Utterance[] = [
  { id: 1, text: "今日は天気がいいですね", timestamp: 1000, speaker: "A" },
  { id: 2, text: "本当にそうですね", timestamp: 2000, speaker: "B" },
  { id: 3, text: "散歩に行きましょうか", timestamp: 3000, speaker: "A" },
];

const current: Utterance = {
  id: 4,
  text: "いいですね、公園に行きましょう",
  timestamp: 4000,
  speaker: "B"
};

const result = await analyze(adapter, history, current, {
  k: 15,
  fdrAlpha: 0.1,
});

console.log(`重要発話: ${result.important.length}件`);
result.important.forEach(imp => {
  console.log(`ID=${imp.id}, score=${imp.score.toFixed(3)}, p=${imp.p?.toFixed(4)}`);
  console.log(`Text: ${imp.text}`);
});
```

### アンカーメモリ使用

```typescript
import { AnchorMemory, analyzeWithAnchors } from '@atlas/core';

const anchorMemory = new AnchorMemory(200);

// セッション1
const result1 = await analyzeWithAnchors(adapter, history1, current1, anchorMemory);
result1.important.forEach(imp => {
  anchorMemory.add({
    id: imp.id,
    text: imp.text,
    score: imp.score,
    ts: imp.timestamp
  });
});

// セッション2（過去のアンカーがスコアをブースト）
const result2 = await analyzeWithAnchors(adapter, history2, current2, anchorMemory);
```

---

## 具体的な会話例によるアルゴリズム解説

### サンプル会話

```
[ID=1] Speaker A (t=0s):   "次回のプロジェクト会議は来週月曜日です"
[ID=2] Speaker B (t=5s):   "了解しました"
[ID=3] Speaker A (t=10s):  "議題は新機能の設計レビューです"
[ID=4] Speaker C (t=20s):  "データベース設計も含まれますか？"
[ID=5] Speaker A (t=30s):  "はい、含まれます"
[ID=6] Speaker B (t=40s):  "では準備しておきます"
→ [ID=7] Speaker C (t=50s): "月曜日のデータベース設計レビュー、資料を用意します"
```

**分析対象:** ID=7の発話が追加されたとき、ID=1～6のどれが重要か？

### パラメータ設定

```typescript
const options = {
  k: 5,              // 直近5発話を候補として評価
  alphaMix: 0.6,     // ΔLoss重視
  halfLifeTurns: 10, // 10ターンで半減
  nullSamples: 20,   // 帰無サンプル20個生成
  fdrAlpha: 0.1,     // p < 0.1 で有意
};
```

---

### ステップ1: Base Loss計算

**目的:** 履歴全体から現在発話を予測する困難度

**計算:**

1. 全発話（ID=1～6）と現在発話（ID=7）のテキストを埋め込みAPIに送信（バッチ）
2. 履歴の重み付き平均埋め込みを計算

```typescript
// 時間減衰重み（最新が最大）
weights = [
  exp(-ln(2)/10 × 6) = 0.66,  // ID=1（6ターン前）
  exp(-ln(2)/10 × 5) = 0.70,  // ID=2（5ターン前）
  exp(-ln(2)/10 × 4) = 0.75,  // ID=3（4ターン前）
  exp(-ln(2)/10 × 3) = 0.80,  // ID=4（3ターン前）
  exp(-ln(2)/10 × 2) = 0.87,  // ID=5（2ターン前）
  exp(-ln(2)/10 × 1) = 0.93,  // ID=6（1ターン前）
]

// 正規化後の重み
normalized_weights = weights / sum(weights) = [0.14, 0.15, 0.16, 0.17, 0.18, 0.20]

// 重み付き平均埋め込み
H̄ = 0.14×vec(ID=1) + 0.15×vec(ID=2) + ... + 0.20×vec(ID=6)

// コサイン類似度
similarity = cos(H̄, vec(ID=7)) = 0.73

// Base Loss
baseLoss = 1 - 0.73 = 0.27
```

**わかること:**
- ID=7は履歴全体からある程度予測可能（similarity=0.73は中程度）
- 完全に新しい話題ではない

---

### ステップ2: Masked Loss計算（並列実行）

**目的:** 各候補発話を除外したときの損失変化を測定

**候補:** 直近k=5発話 → ID=2, 3, 4, 5, 6

#### ID=1をマスク（"次回のプロジェクト会議は来週月曜日です"）

```typescript
filtered_history = [ID=2, 3, 4, 5, 6]  // ID=1を除外

// 重み付き平均（ID=1なし）
H̄_{-1} = 0.18×vec(ID=2) + 0.19×vec(ID=3) + ... + 0.24×vec(ID=6)

similarity_{-1} = cos(H̄_{-1}, vec(ID=7)) = 0.65  // 低下！

maskedLoss(ID=1) = 1 - 0.65 = 0.35
ΔLoss(ID=1) = 0.35 - 0.27 = +0.08  ⭐ 正の大きな値 = 重要
```

**わかること:**
- ID=1（"月曜日"）を除外すると予測精度が大幅に低下
- ID=7は "月曜日" という情報に強く依存している

#### ID=3をマスク（"議題は新機能の設計レビューです"）

```typescript
filtered_history = [ID=1, 2, 4, 5, 6]  // ID=3を除外

similarity_{-3} = cos(H̄_{-3}, vec(ID=7)) = 0.68

maskedLoss(ID=3) = 1 - 0.68 = 0.32
ΔLoss(ID=3) = 0.32 - 0.27 = +0.05  ⭐ 正の値 = やや重要
```

**わかること:**
- ID=3（"設計レビュー"）もやや重要
- ID=7は "レビュー" の文脈にも依存

#### ID=4をマスク（"データベース設計も含まれますか？"）

```typescript
filtered_history = [ID=1, 2, 3, 5, 6]  // ID=4を除外

similarity_{-4} = cos(H̄_{-4}, vec(ID=7)) = 0.62  // 大幅低下！

maskedLoss(ID=4) = 1 - 0.62 = 0.38
ΔLoss(ID=4) = 0.38 - 0.27 = +0.11  ⭐⭐ 最大 = 最重要
```

**わかること:**
- ID=4（"データベース設計"）が最も重要
- ID=7の核心的なトピックを導入した発話

#### ID=2, 5, 6をマスク（相槌・短い応答）

```typescript
// ID=2: "了解しました"
ΔLoss(ID=2) = 0.28 - 0.27 = +0.01  // ほぼゼロ = 冗長

// ID=5: "はい、含まれます"
ΔLoss(ID=5) = 0.30 - 0.27 = +0.03  // 小さい = やや重要

// ID=6: "では準備しておきます"
ΔLoss(ID=6) = 0.29 - 0.27 = +0.02  // 小さい = ほぼ冗長
```

**わかること:**
- 相槌や短い応答は情報量が少ない
- 除外しても予測精度はほとんど変わらない

---

### ステップ3: 時間減衰重み適用

**目的:** 古い発話のスコアを減衰させる

```typescript
// ageWeight = exp(-ln(2)/halfLife × distance)
ageWeight(ID=1) = exp(-ln(2)/10 × 6) = 0.66
ageWeight(ID=2) = exp(-ln(2)/10 × 5) = 0.70
ageWeight(ID=3) = exp(-ln(2)/10 × 4) = 0.75
ageWeight(ID=4) = exp(-ln(2)/10 × 3) = 0.80
ageWeight(ID=5) = exp(-ln(2)/10 × 2) = 0.87
ageWeight(ID=6) = exp(-ln(2)/10 × 1) = 0.93

// 最終スコア = (alphaMix × ΔLoss) × ageWeight
score(ID=1) = (0.6 × 0.08) × 0.66 = 0.032
score(ID=2) = (0.6 × 0.01) × 0.70 = 0.004
score(ID=3) = (0.6 × 0.05) × 0.75 = 0.023
score(ID=4) = (0.6 × 0.11) × 0.80 = 0.053  ⭐ 最大
score(ID=5) = (0.6 × 0.03) × 0.87 = 0.016
score(ID=6) = (0.6 × 0.02) × 0.93 = 0.011
```

**わかること:**
- ID=4が最もスコアが高い（ΔLossも大きく、比較的新しい）
- ID=1は古いため、ΔLossが大きくても減衰している

---

### ステップ4: 帰無分布生成（並列実行）

**目的:** ランダムな履歴でも同様のスコアが出る確率を測定

**手順:**
1. 履歴をシャッフル（20回）
2. 各回で直近k=5発話を選択
3. ΔLossを計算

```typescript
// サンプル1: シャッフル結果 [ID=4, 2, 5, 1, 3]
null_ΔLoss_1 = [0.02, -0.01, 0.01, 0.03, 0.02]  // 5個のΔLoss

// サンプル2: シャッフル結果 [ID=6, 3, 1, 4, 2]
null_ΔLoss_2 = [0.01, 0.02, -0.01, 0.04, 0.01]

// ... (20回繰り返し)

// 全サンプルを結合
null_scores = [0.02, -0.01, 0.01, ..., 0.01]  // 100個（20×5）

// 分布の概要
median(null_scores) = 0.015
MAD(null_scores) = 0.012
```

**わかること:**
- ランダムな履歴でのΔLossは小さい（median=0.015）
- 観測されたスコアが帰無分布から外れているか検定できる

---

### ステップ5: Robust Z変換

**目的:** 外れ値に頑健な標準化で異常度を測定

```typescript
// 全スコア（観測+帰無）を結合
all_scores = [
  0.032,  // ID=1（観測）
  0.004,  // ID=2（観測）
  0.023,  // ID=3（観測）
  0.053,  // ID=4（観測）
  0.016,  // ID=5（観測）
  0.011,  // ID=6（観測）
  ...null_scores  // 100個の帰無スコア
]

// Robust Z変換
median_all = 0.015
MAD_all = 0.012

z_scores = 0.6745 × (all_scores - 0.015) / 0.012

// 観測発話のZ値
z(ID=1) = 0.6745 × (0.032 - 0.015) / 0.012 = +0.96
z(ID=2) = 0.6745 × (0.004 - 0.015) / 0.012 = -0.62
z(ID=3) = 0.6745 × (0.023 - 0.015) / 0.012 = +0.45
z(ID=4) = 0.6745 × (0.053 - 0.015) / 0.012 = +2.14  ⭐⭐ 最大の異常度
z(ID=5) = 0.6745 × (0.016 - 0.015) / 0.012 = +0.06
z(ID=6) = 0.6745 × (0.011 - 0.015) / 0.012 = -0.22
```

**わかること:**
- ID=4のスコアは帰無分布から大きく外れている（z=+2.14）
- ID=1もやや外れている（z=+0.96）
- ID=2, 5, 6は帰無分布内に収まっている

---

### ステップ6: p値計算

**目的:** 帰無分布を超える確率（統計的有意性）

```typescript
// 帰無分布のZ値のECDF（経験累積分布関数）を構築
z_null = z_scores.slice(6)  // 帰無サンプルのZ値100個
F_0 = ecdf(z_null)

// p値 = P(Z_null > z_obs) = 1 - F_0(z_obs)
p(ID=1) = 1 - F_0(+0.96) = 1 - 0.83 = 0.17  // 有意でない
p(ID=2) = 1 - F_0(-0.62) = 1 - 0.27 = 0.73  // 有意でない
p(ID=3) = 1 - F_0(+0.45) = 1 - 0.67 = 0.33  // 有意でない
p(ID=4) = 1 - F_0(+2.14) = 1 - 0.98 = 0.02  ⭐⭐ 有意！ (p < 0.1)
p(ID=5) = 1 - F_0(+0.06) = 1 - 0.52 = 0.48  // 有意でない
p(ID=6) = 1 - F_0(-0.22) = 1 - 0.41 = 0.59  // 有意でない
```

**わかること:**
- ID=4のみがp < fdrAlpha (0.1) を満たす → **統計的に有意**
- 他の発話はランダムな履歴でも同程度のスコアが出る可能性が高い

---

### ステップ7: 最終判定

**結果:**

```typescript
{
  important: [
    {
      id: 4,
      text: "データベース設計も含まれますか？",
      speaker: "C",
      timestamp: 20000,
      score: 0.053,
      p: 0.02,
      rank: 1,
      detail: {
        baseLoss: 0.27,
        maskedLoss: 0.38,
        deltaLoss: 0.11,
        ageWeight: 0.80,
        rawScore: 0.066,
        finalScore: 0.053
      }
    }
  ],
  scored: [
    { id: 4, score: 0.053, p: 0.02, rank: 1, ... },
    { id: 1, score: 0.032, p: 0.17, rank: 2, ... },
    { id: 3, score: 0.023, p: 0.33, rank: 3, ... },
    { id: 5, score: 0.016, p: 0.48, rank: 4, ... },
    { id: 6, score: 0.011, p: 0.59, rank: 5, ... },
    { id: 2, score: 0.004, p: 0.73, rank: 6, ... },
  ],
  anchorCount: 1
}
```

**解釈:**

1. **ID=4（"データベース設計も含まれますか？"）が重要発話として検出**
   - ID=7（"月曜日のデータベース設計レビュー、資料を用意します"）の核心となるトピックを導入
   - この発話がなければ、ID=7の "データベース設計" という文脈が予測困難

2. **ID=1（"次回のプロジェクト会議は来週月曜日です"）も高スコアだが有意でない**
   - ΔLossは大きいが、時間減衰により減衰
   - p値が閾値を超えており、統計的にはランダムと区別できない

3. **ID=2, 5, 6は相槌・応答で情報量が少ない**
   - 除外しても予測精度はほとんど変わらない

4. **依存関係グラフ:**
   ```
   [ID=4] ───→ [ID=7]
     │
     └─ "データベース設計" という重要な文脈を提供
   ```

---

### このアルゴリズムから得られる洞察

#### 1. コンテキスト依存性の定量化
- 現在の発話がどの過去の発話に依存しているかを数値化
- 会話の因果構造を明らかにする

#### 2. 情報量の客観的評価
- 発話の長さや話者の地位に依存せず、純粋に情報的価値を測定
- 相槌や冗長な発言を自動的にフィルタリング

#### 3. 統計的な信頼性
- p値による有意性検定で、偽陽性（ノイズを重要と誤認）を制御
- FDR制御により、複数検定の問題を回避

#### 4. リアルタイム適用可能性
- 発話が追加されるたびに即座に分析可能
- 学習フェーズ不要で、あらゆる会話に適用可能

#### 5. 実用的な応用
- **会議サマリ生成**: 重要発話のみを抽出して要約
- **注意喚起通知**: ユーザーが見逃した重要発話をハイライト
- **会話検索**: 重要発話を起点に会話全体を理解
- **依存関係可視化**: 会話の流れをグラフで表現

---

## 参考文献

### アルゴリズム

- **Masked Language Modeling**: Devlin et al., "BERT: Pre-training of Deep Bidirectional Transformers" (2018)
- **Permutation Testing**: Ojala & Garriga, "Permutation Tests for Studying Classifier Performance" (2010)
- **MMR**: Carbonell & Goldstein, "The Use of MMR, Diversity-Based Reranking" (1998)

### 統計

- **Benjamini-Hochberg FDR**: Benjamini & Hochberg, "Controlling the False Discovery Rate" (1995)
- **Robust Statistics**: Rousseeuw & Croux, "Alternatives to the Median Absolute Deviation" (1993)

### 実装

- **OpenAI Embeddings API**: https://platform.openai.com/docs/guides/embeddings
- **Cosine Similarity**: https://en.wikipedia.org/wiki/Cosine_similarity

---

## ライセンス

MIT

---

## 貢献

Issue/PRを歓迎します。

GitHub: https://github.com/your-org/atlas
